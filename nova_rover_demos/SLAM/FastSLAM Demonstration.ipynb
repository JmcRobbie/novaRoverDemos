{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SLAM Demonstation using FastSLAM algorithm\n",
    "### by Melbourne Space Program \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Acknowledgement\n",
    "\n",
    "We acknoledge that the code below is primarily adopted from the Python Robotics Repo at https://github.com/AtsushiSakai/PythonRobotics#fastslam-10\n",
    "\n",
    "by Kaif Ashan, Kenneth Huynh and Peter Shi from the Melbourne Space Program.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction\n",
    "\n",
    "FastSlam is variation of SLAM which uses Particle filters, a.k.a Sequential Monte Carlo, to solve the SLAM problem. It uses a feature based maps or occupancy grids"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Predicting Particles using the Motion Model\n",
    "\n",
    "A class which represents all the particles generated by the particle filter. In FastSLAM usually a set of particles are generated through a model which later are updated by cross-checking with observastions made through sensors/know data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Particle:\n",
    "\n",
    "    def __init__(self, N_LM):\n",
    "        # * As the number of particles increase their weights decrease\n",
    "        self.w = 1.0 / N_PARTICLE\n",
    "        self.x = 0.0\n",
    "        self.y = 0.0\n",
    "        self.yaw = 0.0\n",
    "        # landmark x-y positions\n",
    "        self.lm = np.zeros((N_LM, LM_SIZE))\n",
    "        # landmark position covariance\n",
    "        self.lmP = np.zeros((N_LM * LM_SIZE, LM_SIZE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def motion_model(x, u):\n",
    "    # The state matrix \n",
    "    # In the demo only an identity matrix \n",
    "    F = np.array([[1.0, 0, 0],\n",
    "                  [0, 1.0, 0],\n",
    "                  [0, 0, 1.0]])\n",
    "\n",
    "    # Input matrix\n",
    "    B = np.array([[DT * math.cos(x[2, 0]), 0],\n",
    "                  [DT * math.sin(x[2, 0]), 0],\n",
    "                  [0.0, DT]])\n",
    "\n",
    "    # Update the position of the rover based on the controls \n",
    "    # * Doesn't adjust for any noise\n",
    "    x = F @ x + B @ u\n",
    "\n",
    "    # Convert the angle into the first quadrant \n",
    "    x[2, 0] = pi_2_pi(x[2, 0])\n",
    "\n",
    "    return x\n",
    "\n",
    "    def pi_2_pi(angle):\n",
    "    return (angle + math.pi) % (2 * math.pi) - math.pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_particles(particles, u):\n",
    "\n",
    "    # For each particle produce a new sample\n",
    "    for i in range(N_PARTICLE):\n",
    "        px = np.zeros((STATE_SIZE, 1))\n",
    "        px[0, 0] = particles[i].x\n",
    "        px[1, 0] = particles[i].y\n",
    "        px[2, 0] = particles[i].yaw\n",
    "        # adding noise to the original control\n",
    "        ud = u + (np.random.randn(1, 2) @ R ** 0.5).T\n",
    "        # Run the state of particles and the noisy controls through the motion model  \n",
    "        px = motion_model(px, ud)\n",
    "        # Update the new state of the particles \n",
    "        particles[i].x = px[0, 0]\n",
    "        particles[i].y = px[1, 0]\n",
    "        particles[i].yaw = px[2, 0]\n",
    "\n",
    "    return particles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################### update_with_observation ###################### "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Description to be added by Peter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_with_observation(particles, z):\n",
    "    for iz in range(len(z[0, :])):\n",
    "\n",
    "        lmid = int(z[2, iz])\n",
    "\n",
    "        for ip in range(N_PARTICLE):\n",
    "            # new landmark\n",
    "            if abs(particles[ip].lm[lmid, 0]) <= 0.01:\n",
    "                particles[ip] = add_new_lm(particles[ip], z[:, iz], Q)\n",
    "            # known landmark\n",
    "            else:\n",
    "                w = compute_weight(particles[ip], z[:, iz], Q)\n",
    "                particles[ip].w *= w\n",
    "                particles[ip] = update_landmark(particles[ip], z[:, iz], Q)\n",
    "\n",
    "    return particles\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Description to be added by Peter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_new_lm(particle, z, Q_cov):\n",
    "    r = z[0]\n",
    "    b = z[1]\n",
    "    lm_id = int(z[2])\n",
    "\n",
    "    s = math.sin(pi_2_pi(particle.yaw + b))\n",
    "    c = math.cos(pi_2_pi(particle.yaw + b))\n",
    "\n",
    "    particle.lm[lm_id, 0] = particle.x + r * c\n",
    "    particle.lm[lm_id, 1] = particle.y + r * s\n",
    "\n",
    "    # covariance\n",
    "    Gz = np.array([[c, -r * s],\n",
    "                   [s, r * c]])\n",
    "\n",
    "    particle.lmP[2 * lm_id:2 * lm_id + 2] = Gz @ Q_cov @ Gz.T\n",
    "\n",
    "    return particle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Description to be added by Peter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_weight(particle, z, Q_cov):\n",
    "    lm_id = int(z[2])\n",
    "    xf = np.array(particle.lm[lm_id, :]).reshape(2, 1)\n",
    "    Pf = np.array(particle.lmP[2 * lm_id:2 * lm_id + 2])\n",
    "    zp, Hv, Hf, Sf = compute_jacobians(particle, xf, Pf, Q_cov)\n",
    "\n",
    "    dx = z[0:2].reshape(2, 1) - zp\n",
    "    dx[1, 0] = pi_2_pi(dx[1, 0])\n",
    "\n",
    "    try:\n",
    "        invS = np.linalg.inv(Sf)\n",
    "    except np.linalg.linalg.LinAlgError:\n",
    "        print(\"singuler\")\n",
    "        return 1.0\n",
    "\n",
    "    num = math.exp(-0.5 * dx.T @ invS @ dx)\n",
    "    den = 2.0 * math.pi * math.sqrt(np.linalg.det(Sf))\n",
    "\n",
    "    w = num / den\n",
    "\n",
    "    return w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Description to be added by Peter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_landmark(particle, z, Q_cov):\n",
    "    lm_id = int(z[2])\n",
    "    xf = np.array(particle.lm[lm_id, :]).reshape(2, 1)\n",
    "    Pf = np.array(particle.lmP[2 * lm_id:2 * lm_id + 2, :])\n",
    "\n",
    "    zp, Hv, Hf, Sf = compute_jacobians(particle, xf, Pf, Q)\n",
    "\n",
    "    dz = z[0:2].reshape(2, 1) - zp\n",
    "    dz[1, 0] = pi_2_pi(dz[1, 0])\n",
    "\n",
    "    xf, Pf = update_kf_with_cholesky(xf, Pf, dz, Q_cov, Hf)\n",
    "\n",
    "    particle.lm[lm_id, :] = xf.T\n",
    "    particle.lmP[2 * lm_id:2 * lm_id + 2, :] = Pf\n",
    "\n",
    "    return particle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################### resampling ###################### "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}